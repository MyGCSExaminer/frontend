from fastapi import FastAPI, HTTPException, UploadFile, File, Form
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse
import openai, os, uuid, time, asyncio, json, sys, traceback
from io import BytesIO
import mimetypes
import psycopg2
from psycopg2.extras import RealDictCursor

# =========================================================
# OPENAI CREDS (PASTE YOUR REAL KEY)
# =========================================================
openai.api_key = "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"
ASSISTANT_ID   = "asst_SdvuLbm79fKpvJyZZIVYvVyh


# Assistants
DEFAULT_ASSISTANT_ID = "asst_SdvuLbm79fKpvJyZZIVYvVyh"  # default/fallback
ALLOWED_ASSISTANTS = {
    "asst_SdvuLbm79fKpvJyZZIVYvVyh": "Default Assistant",
    "asst_pHB7OjRMiEoJJvnKtdyXamp3": "Second Assistant",
}

# =========================================================
# DATABASE (Render Postgres) — set DATABASE_URL env var
# =========================================================
DB_URL = os.getenv("DATABASE_URL")  # Render Postgres → External Connection URL

def db():
    if not DB_URL:
        raise RuntimeError("DATABASE_URL not set. Add it in Render → Environment.")
    return psycopg2.connect(DB_URL, cursor_factory=RealDictCursor)

def init_db():
    try:
        with db() as conn, conn.cursor() as cur:
            cur.execute("""
            CREATE TABLE IF NOT EXISTS threads (
              user_id TEXT NOT NULL,
              assistant_id TEXT NOT NULL,
              thread_id TEXT NOT NULL,
              updated_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
              PRIMARY KEY (user_id, assistant_id)
            );
            """)
            conn.commit()
            print("[db] threads table ready", flush=True)
    except Exception as e:
        print("[db] init error:", e, flush=True)

if DB_URL:
    init_db()
else:
    print("[WARN] DATABASE_URL not set — persistence disabled until you add it.", flush=True)

# =========================================================
# FASTAPI + CORS
# =========================================================
app = FastAPI(title="Assistant Backend (DB-persistent, multi-assistant)")
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # when stable, restrict to your Vercel origin
    allow_methods=["POST", "OPTIONS", "GET"],
    allow_headers=["*"],
)

# =========================================================
# HELPERS
# =========================================================
def log(*a): print(*a, file=sys.stdout, flush=True)

def rate_limit_ok(user_id: str, max_per_hour: int = 40) -> bool:
    # simple file-backed limiter per user
    PATH = "rate_store.json"
    now = time.time()
    try:
        data = json.load(open(PATH))
    except Exception:
        data = {}
    calls = data.get(user_id, [])
    calls = [t for t in calls if now - t < 3600]
    if len(calls) >= max_per_hour:
        return False
    calls.append(now)
    data[user_id] = calls
    json.dump(data, open(PATH, "w"))
    return True

def extract_text_from_message(msg) -> str:
    parts = []
    try:
        for block in getattr(msg, "content", []) or []:
            if hasattr(block, "text") and getattr(block.text, "value", None):
                parts.append(block.text.value)
            elif isinstance(block, dict):
                val = (block.get("text") or {}).get("value")
                if isinstance(val, str): parts.append(val)
    except Exception:
        pass
    return "\n".join(parts).strip()

async def wait_for_run(thread_id: str, run_id: str, timeout_s: int = 90):
    start = time.time(); interval = 0.6
    while True:
        run = openai.beta.threads.runs.retrieve(thread_id=thread_id, run_id=run_id)
        status = getattr(run, "status", None) or (isinstance(run, dict) and run.get("status"))
        if status not in {"queued", "in_progress"}:
            return run
        if time.time() - start > timeout_s:
            try: run.status = "timeout"; return run
            except Exception: return {"status": "timeout"}
        await asyncio.sleep(interval); interval = min(interval + 0.2, 2.0)

def run_error_detail(run) -> str:
    last_err = getattr(run, "last_error", None)
    if isinstance(last_err, dict): return last_err.get("message") or last_err.get("code") or ""
    if last_err and hasattr(last_err, "message"): return getattr(last_err, "message")
    if isinstance(run, dict):
        le = run.get("last_error"); 
        if isinstance(le, dict): return le.get("message") or le.get("code") or ""
    return ""

def is_pdf_upload(file_obj: UploadFile) -> bool:
    mt = file_obj.content_type or mimetypes.guess_type(file_obj.filename)[0] or ""
    return "pdf" in mt.lower() or (file_obj.filename or "").lower().endswith(".pdf")

def pdf_to_text_bytes(raw_bytes: bytes) -> bytes:
    # Try PyPDF first (fast), then pdfminer.six (broader)
    try:
        from pypdf import PdfReader
        reader = PdfReader(BytesIO(raw_bytes))
        out = []
        for i, page in enumerate(reader.pages):
            txt = (page.extract_text() or "").strip()
            out.append(f"\n\n=== Page {i+1} ===\n{txt}")
        combined = "\n".join(out).strip()
        if combined:
            return combined.encode("utf-8")
    except Exception:
        pass
    try:
        from pdfminer.high_level import extract_text as pdfminer_extract_text
        combined = pdfminer_extract_text(BytesIO(raw_bytes)) or ""
        if combined.strip():
            return combined.encode("utf-8")
    except Exception:
        pass
    return raw_bytes  # fallback

def get_or_create_thread(user_id: str, assistant_id: str) -> str:
    # Reuse per (user_id, assistant_id); create if missing
    if not DB_URL:
        t = openai.beta.threads.create()
        log("[WARN] No DATABASE_URL; returning new thread each call:", t.id)
        return t.id
    with db() as conn, conn.cursor() as cur:
        cur.execute("SELECT thread_id FROM threads WHERE user_id=%s AND assistant_id=%s",
                    (user_id, assistant_id))
        row = cur.fetchone()
        if row:
            return row["thread_id"]
        t = openai.beta.threads.create()
        cur.execute("""
            INSERT INTO threads (user_id, assistant_id, thread_id)
            VALUES (%s, %s, %s)
            ON CONFLICT (user_id, assistant_id)
            DO UPDATE SET thread_id=EXCLUDED.thread_id, updated_at=NOW()
        """, (user_id, assistant_id, t.id))
        conn.commit()
        return t.id

# =========================================================
# ENDPOINTS
# =========================================================
@app.get("/health")
def health(): return {"status": "ok"}

@app.post("/chat")
async def chat(
    message: str = Form(""),
    user_id: str = Form(None),        # stable ID from frontend (uuid)
    assistant_id: str = Form(None),   # optional; defaults below
    file: UploadFile = File(None),
):
    try:
        user_id = user_id or str(uuid.uuid4())

        # Validate/resolve assistant
        assistant_id = assistant_id or DEFAULT_ASSISTANT_ID
        if assistant_id not in ALLOWED_ASSISTANTS:
            # fallback to default (or raise 400 if you prefer strict)
            assistant_id = DEFAULT_ASSISTANT_ID

        if not message and not file:
            raise HTTPException(status_code=400, detail="Message or file required.")
        if not rate_limit_ok(user_id):
            raise HTTPException(status_code=429, detail="Rate limit exceeded.")

        thread_id = get_or_create_thread(user_id, assistant_id)

        # Optional file upload (PDF → text for reliability/cost)
        attachments = None
        if file:
            raw = await file.read()
            file_bytes = pdf_to_text_bytes(raw) if is_pdf_upload(file) else raw
            fname = (file.filename or "upload")
            if is_pdf_upload(file) and file_bytes is not raw:
                base = fname.rsplit(".", 1)[0]; fname = f"{base}.txt"
            uploaded = openai.files.create(
                file=BytesIO(file_bytes),
                purpose="assistants",
                filename=fname
            )
            attachments = [{"file_id": uploaded.id}]

        # Send user message
        openai.beta.threads.messages.create(
            thread_id=thread_id,
            role="user",
            content=message or (f"Attached file: {getattr(file,'filename','')}" if file else ""),
            attachments=attachments
        )

        # Run & wait
        run = openai.beta.threads.runs.create(thread_id=thread_id, assistant_id=assistant_id)
        run = await wait_for_run(thread_id, getattr(run, "id", None) or run.get("id"))
        status = getattr(run, "status", None) or (isinstance(run, dict) and run.get("status"))

        if status == "failed":
            reason = run_error_detail(run)
            raise HTTPException(status_code=502, detail=f"Assistant run failed. {('Reason: ' + reason) if reason else 'Check model/tools/billing.'}")
        if status == "timeout":
            raise HTTPException(status_code=504, detail="Run timed out. Enable tools or reduce file size.")
        if status != "completed":
            raise HTTPException(status_code=502, detail=f"Assistant run ended with status={status}. Check assistant settings & tools.")

        # Fetch reply
        msgs = openai.beta.threads.messages.list(thread_id=thread_id)
        assistant_msgs = [m for m in msgs.data if getattr(m, "role", "") == "assistant"]
        if not assistant_msgs:
            raise HTTPException(status_code=500, detail="Assistant did not generate a reply. Verify model/instructions/tools/billing.")
        reply = extract_text_from_message(assistant_msgs[-1]) or "[No text content returned]"

        return JSONResponse({
            "response": reply,
            "user_id": user_id,
            "assistant_id": assistant_id,
            "thread_id": thread_id
        })

    except HTTPException:
        raise
    except Exception as e:
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=f"Server error: {e}")
